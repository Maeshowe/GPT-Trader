-e \n\n=== FILE: ./sector_runner.py ===
#!/usr/bin/env python3
"""
Sector prompt futtatÃ¡sa, Score kinyerÃ©se Ã©s visszaÃ­rÃ¡sa inputs/sector_input.json-be
"""

import os, json, re
from pathlib import Path
from dotenv import load_dotenv
from jinja2 import Template
from openai import OpenAI

BASE_DIR = Path(__file__).resolve().parent
load_dotenv(override=True)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
model  = os.getenv("OPENAI_MODEL", "gpt-4o")

# â”€â”€ 1) Input JSON betÃ¶ltÃ©s
sector_path = BASE_DIR / "inputs/sector_input.json"
with open(sector_path) as f:
    data = json.load(f)

# â”€â”€ 2) Prompt renderelÃ©s
with open(BASE_DIR / "prompts/sector_prompt.j2") as f:
    prompt = Template(f.read()).render(**data)

# â”€â”€ 3) GPT-hÃ­vÃ¡s
response = client.chat.completions.create(
    model=model,
    messages=[{"role": "user", "content": prompt}],
    temperature=0,
    max_tokens=600,
)
output = response.choices[0].message.content.strip()
print("ğŸ§¾ GPT-vÃ¡lasz (Sector):\n", output)

# â”€â”€ 4) Score kinyerÃ©se regex-szel
m = re.search(r"Score:\s*(\d+)", output)
if m:
    data["sector_score"] = int(m.group(1))
    with open(sector_path, "w") as f:
        json.dump(data, f, indent=2)
    print(f"âœ… sector_score ({data['sector_score']}) mentve a {sector_path} fÃ¡jlba")
else:
    print("âš ï¸  Nem talÃ¡ltam Score-t a vÃ¡laszban.")-e \n\n=== FILE: ./prompt_runner.py ===
#!/usr/bin/env python3
"""
Firm prompt futtatÃ¡sa:
â€¢ GPT-score kinyerÃ©se
â€¢ SHAP-szerÅ± feature-hatÃ¡sok kiszÃ¡mÃ­tÃ¡sa (fix lineÃ¡ris sÃºlyokkal)
â€¢ EredmÃ©ny visszaÃ­rÃ¡sa inputs/firm_inputs.json-be
"""

import os, json, re
from pathlib import Path
from dotenv import load_dotenv
from jinja2 import Template
from openai import OpenAI

# â”€â”€ BeÃ¡llÃ­tÃ¡sok --------------------------------------------------------------
BASE = Path(__file__).resolve().parent
load_dotenv(override=True)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
MODEL  = os.getenv("OPENAI_MODEL", "gpt-4o")

# â”€â”€ 1) Bemenet ---------------------------------------------------------------
firm_path = BASE / "inputs/firm_inputs.json"
firm_records = json.load(open(firm_path))

# Itt pÃ©ldakÃ©nt csak a legfrissebb 1. rekordot dolgozzuk fel; vÃ©gig is iterÃ¡lhatnÃ¡l.
rec = firm_records[0]

# â”€â”€ 2) Prompt renderelÃ©s -----------------------------------------------------
prompt = Template(open(BASE / "prompts/firm_prompt.j2").read()).render(**rec)

resp = client.chat.completions.create(
    model=MODEL,
    messages=[{"role": "user", "content": prompt}],
    temperature=0,
    max_tokens=700
).choices[0].message.content.strip()

print("ğŸ§¾ GPT-vÃ¡lasz (Firm):\n", resp)

# â”€â”€ 3) Score kinyerÃ©se -------------------------------------------------------
m = re.search(r"Score:\s*(\d+)", resp)
rec["firm_score"] = int(m.group(1)) if m else None

# â”€â”€ 4) SHAP-szerÅ± magyarÃ¡zat (fix sÃºlyok) ------------------------------------
feature_weights = {
    "P/E": 0.20,
    "PEG": -0.10,
    "Beta": -0.10,
    "ROE": 0.40,
    "Quick Ratio": 0.30
}
fin = rec["firm_financials_json"]
rec["firm_shap"] = {
    k: round(feature_weights[k] * fin.get(k, 0), 2) for k in feature_weights
}

# â”€â”€ 5) VisszaÃ­rÃ¡s a JSON-listÃ¡ba -------------------------------------------
firm_records[0] = rec
json.dump(firm_records, open(firm_path, "w"), indent=2)
print(f"âœ… firm_score ({rec['firm_score']}), SHAP-Ã©rtÃ©kek mentve a {firm_path} fÃ¡jlba")-e \n\n=== FILE: ./run_prompts.py ===
#!/usr/bin/env python3
"""
Aszinkron batch futtatÃ³:
â€¢ Sector-score  (3 rekord)    â€“ async, timeout+retry
â€¢ Firm-score + SHAP (9 rekord)â€“ async, timeout+retry, max 5 pÃ¡rhuzamos
"""

import os, json, re, asyncio, time
from pathlib import Path
from dotenv import load_dotenv
from jinja2 import Template
from openai import AsyncOpenAI, APITimeoutError, RateLimitError

BASE = Path(__file__).resolve().parent
load_dotenv(override=True)
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
MODEL  = os.getenv("OPENAI_MODEL","gpt-4o")

MAX_CONCURRENCY = 2
REQ_TIMEOUT     = 60        # mp
RETRY_LIMIT     = 4
RETRY_BACKOFF   = 8         # mp

# â”€â”€ GPT hÃ­vÃ¡s retry-val, timeout-tal ----------------------------------------
async def gpt_call(prompt, temperature=0):
    for attempt in range(1, RETRY_LIMIT+1):
        try:
            resp = await client.chat.completions.create(
                model=MODEL,
                messages=[{"role":"user","content":prompt}],
                temperature=temperature,
                max_tokens=700,
                timeout=REQ_TIMEOUT            # 1.3.x paramÃ©ter
            )
            return resp.choices[0].message.content
        except (APITimeoutError, RateLimitError) as e:
            wait = RETRY_BACKOFF * attempt
            print(f"âš ï¸  Retry {attempt}/{RETRY_LIMIT} in {wait}s â€“ {e}")
            await asyncio.sleep(wait)
    raise RuntimeError("GPT call failed after retries")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1) Sector batch (async)                                                     -
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def run_sectors_async():
    path = BASE/"inputs/sector_inputs.json"
    sectors = json.load(open(path))
    tpl = Template(open(BASE/"prompts/sector_prompt.j2").read())

    async def job(s):
        print(f"â†’ Sector: {s['name']}")
        out = await gpt_call(tpl.render(**s))
        m = re.search(r"Score:\s*(\d+)", out)
        s["sector_score"] = int(m.group(1)) if m else None
        print(f"âœ“ {s['name']} score = {s['sector_score']}")

    await asyncio.gather(*[job(s) for s in sectors])
    json.dump(sectors, open(path,"w"), indent=2)
    print("âœ… Sector-scores frissÃ­tve.")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2) Firm batch (async)                                                       -
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FIRM_W = {"P/E":0.2,"PEG":-0.1,"Beta":-0.1,"ROE":0.4,"Quick Ratio":0.3}
firm_tpl = Template(open(BASE/"prompts/firm_prompt.j2").read())

async def run_firms_async():
    path = BASE/"inputs/firm_inputs.json"
    firms = json.load(open(path))
    sem = asyncio.Semaphore(MAX_CONCURRENCY)

    async def job(f):
        if f.get("firm_score") and f.get("firm_shap"):
            print(f"âŒ› Skip {f['ticker']} â€“ already done")
            return
        async with sem:
            print(f"â†’ GPT {f['ticker']}")
            out = await gpt_call(firm_tpl.render(**f))
            m = re.search(r"Score:\s*(\d+)", out)
            f["firm_score"] = int(m.group(1)) if m else None
            fin = f["firm_financials_json"]
            f["firm_shap"] = {k: round(FIRM_W[k]*fin.get(k,0),2) for k in FIRM_W}
            print(f"âœ“ {f['ticker']} score = {f['firm_score']}")

    await asyncio.gather(*[job(f) for f in firms])
    json.dump(firms, open(path,"w"), indent=2)
    print("âœ… Firm-scores + SHAP frissÃ­tve.")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main async fÃ¼ggvÃ©ny - EZ A KULCS!
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async def main():
    """FÅ‘program - egyetlen event loop-ban futtatja mindkÃ©t batch-et"""
    t0 = time.time()
    
    # SzekvenciÃ¡lisan futtatjuk Å‘ket ugyanabban az event loop-ban
    await run_sectors_async()
    await run_firms_async()
    
    print(f"â±ï¸  Ã–sszidÅ‘: {round(time.time()-t0,1)} mp")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    # Csak egyetlen asyncio.run() hÃ­vÃ¡s!
    asyncio.run(main())-e \n\n=== FILE: ./backtest_rebal.py ===
#!/usr/bin/env python3
"""
Back-test kÃ©t stratÃ©giÃ¡ra ugyanazzal a Stooq-price feed-del
(1) Buy-&-hold   (BH)
(2) Havi rebalansz hÃ³nap-utolsÃ³ kereskedÃ©si napjÃ¡n   (REB)

â€¢ Bemenet : outputs/portfolio_latest.json   (Weight %)
â€¢ Kimenet : outputs/backtest_rebal_equity.json
            outputs/backtest_rebal_stats.json
"""
import warnings, pandas as pd
warnings.simplefilter("ignore", FutureWarning)

import json, datetime, pandas as pd
from pathlib import Path
from pandas_datareader import data as pdr

BASE   = Path(__file__).resolve().parent
PORT   = json.load(open(BASE/"outputs/portfolio_latest.json"))["table"]

# â”€â”€ ParamÃ©terek â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
START = "2023-01-01"
END   = datetime.date.today().isoformat()
BENCH = "SPY"
UNIT  = 1_000_000                    # indulÃ³ portfÃ³liÃ³ USD

# â”€â”€ Ticker & Weight tisztÃ­tÃ¡s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
clean  = lambda s: s.replace("\xa0", "").strip().upper()
weights0 = {clean(r["Asset"]): float(r["Weight (%)"])/100 for r in PORT}
tickers  = list(weights0) + [BENCH]

# â”€â”€ Ãrfolyamok Stooq-rÃ³l â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def stooq(tks):
    df = pdr.DataReader([t + ".US" for t in tks], "stooq", START, END)["Close"]
    df.columns = [c.split(".")[0] for c in df.columns]
    return df.sort_index()

px = stooq(tickers).dropna(how="all")
missing = [t for t in weights0 if t not in px.columns]
for t in missing: weights0.pop(t)
if not weights0:
    raise RuntimeError("No valid price data for portfolio tickers")

# â”€â”€ Helper: equity-curve szÃ¡mÃ­tÃ¡sa sÃºlysorozatbÃ³l â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def equity_from_weights(price_df: pd.DataFrame, weight_df: pd.DataFrame):
    """price_df: daily Close; weight_df: daily weights (sorÃ¶sszeg =1)"""
    w_aligned = weight_df.reindex(price_df.index).fillna(method="ffill")
    daily_ret = price_df.pct_change().fillna(0)
    port_ret  = (w_aligned * daily_ret).sum(axis=1)
    equity    = (1 + port_ret).cumprod() * UNIT
    return equity

# â”€â”€ (1) Buy-&-hold (BH) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
alloc_qty = {t: weights0[t] * UNIT / px[t].iloc[0] for t in weights0}
bh_equity = (px[list(weights0)] * pd.Series(alloc_qty)).sum(axis=1)

# â”€â”€ (2) Havi rebalansz (REB) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   â€¢ minden hÃ³nap utolsÃ³ valid kereskedÃ©si napjÃ¡n weights0 szerint ÃºjrasÃºlyoz
month_ends = px.index.to_series().groupby(px.index.to_period("M")).last()
w_rebal = pd.DataFrame(index=month_ends, columns=weights0.keys()).fillna(0.0)
for t in weights0: w_rebal[t] = weights0[t]          # fix sÃºly-profil
reb_equity = equity_from_weights(px[list(weights0)], w_rebal)

# â”€â”€ Benchmark (BH-stÃ­lusÃº SPY) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bench = px[BENCH] / px[BENCH].iloc[0] * UNIT

# â”€â”€ MetrikÃ¡k â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def stats(ts):
    yrs = (ts.index[-1] - ts.index[0]).days / 365.25
    cagr   = (ts.iloc[-1]/ts.iloc[0])**(1/yrs) - 1
    dd     = (ts/ts.cummax() - 1).min()
    sharpe = ((ts.pct_change().dropna()).agg(["mean","std"])).pipe(
        lambda s: (s["mean"]/s["std"])*252**0.5 if s["std"] else 0
    )
    return {"CAGR": round(cagr*100,2), "MaxDD": round(dd*100,2), "Sharpe": round(sharpe,2)}

stats_out = {
    "Buy&Hold":  stats(bh_equity),
    "Rebalance": stats(reb_equity),
    "Benchmark": stats(bench)
}

# â”€â”€ MentÃ©s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
out_dir = BASE/"outputs"; out_dir.mkdir(exist_ok=True)
pd.DataFrame({
    "BH":  bh_equity,
    "REB": reb_equity,
    "SPY": bench
}).to_json(out_dir/"backtest_rebal_equity.json", orient="split", date_format="iso")

json.dump(stats_out, open(out_dir/"backtest_rebal_stats.json","w"), indent=2)
print("âœ… Rebalansz back-test elkÃ©szÃ¼lt â€¢ outputs/backtest_rebal_*")-e \n\n=== FILE: ./dashboard/app.py ===
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPT Portfolio Dashboard â€“ minden modul + rugalmas Sector Score forrÃ¡s
"""
import json, datetime, pandas as pd
from pathlib import Path
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Path setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = Path(__file__).resolve().parent.parent
OUT  = ROOT / "outputs"
INP  = ROOT / "inputs"

SECTOR_SCORES = OUT / "sector_scores.json"      # Ãºj
SECTOR_INPUT  = INP / "sector_inputs.json"      # rÃ©gi

FIRM_FILE   = INP / "firm_inputs.json"
PORT_FILE   = OUT / "portfolio_latest.json"
SENT_FILE   = OUT / "news_sentiment.json"
BH_EQ_FILE  = OUT / "backtest_equity.json"
BH_ST_FILE  = OUT / "backtest_stats.json"
REB_EQ_FILE = OUT / "backtest_rebal_equity.json"
REB_ST_FILE = OUT / "backtest_rebal_stats.json"
RISK_FILE   = OUT / "portfolio_risk_budget.json"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streamlit   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="GPT Portfolio Dashboard", layout="wide")
st.sidebar.header("ğŸ“Š GPT Portfolio Dashboard")
st.sidebar.markdown(f"**DÃ¡tum:** {datetime.date.today()}")

# ---------- helper --------------------------------------------------------
def read_json(path: Path, orient_split_ok: bool = True) -> pd.DataFrame:
    if not path.exists() or path.stat().st_size < 3:
        return pd.DataFrame()
    try:
        return pd.read_json(path)
    except ValueError:
        if orient_split_ok:
            try:
                return pd.read_json(path, orient="split")
            except Exception:
                return pd.DataFrame()
        return pd.DataFrame()

# â•”â•â•â•â•â•â•â•â•â•  Sector Scores  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
df_sector = read_json(SECTOR_SCORES)
if df_sector.empty:                         # fallback rÃ©gi forrÃ¡sra
    df_sector = pd.DataFrame([
        {"Sector": s["name"].title(), "Score": s.get("sector_score", 0)}
        for s in read_json(SECTOR_INPUT, orient_split_ok=False).to_dict(orient="records")
    ])

if not df_sector.empty:
    st.subheader("Sector Scores")
    st.dataframe(df_sector, use_container_width=True)
    st.plotly_chart(px.bar(df_sector, x="Sector", y="Score",
                           title="Sector Score Comparison"),
                    use_container_width=True)
else:
    st.info("Nincs sector score â€“ futtasd a sector_runner promptot.")

# â•”â•â•â•â•â•â•â•â•â•  Top 20 Firm Scores  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
df_firm = read_json(FIRM_FILE, orient_split_ok=False)
if not df_firm.empty:
    top20 = df_firm.nlargest(20, "firm_score")
    st.subheader("Top 20 Firm Scores")
    st.dataframe(top20[["ticker", "sector", "firm_score"]],
                 use_container_width=True)

    st.plotly_chart(
        px.bar(top20.sort_values("firm_score"),
               x="firm_score", y="ticker", orientation="h",
               title="Top 20 Firm Scores"),
        use_container_width=True
    )

# â•”â•â•â•â•â•â•â•â•â•  News Sentiment  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
df_sent = read_json(SENT_FILE)
if {"ticker", "avg_sent"}.issubset(df_sent.columns) and not df_sent.empty:
    st.subheader("7-day Average News Sentiment")
    st.bar_chart(df_sent.set_index("ticker")["avg_sent"],
                 height=250, use_container_width=True)
    st.caption("Cut-off < âˆ’0.05 â†’ âˆ’30 % weight (Edge-jelzÃ©s)")
else:
    st.info("Nincs hÃ­r-szentiment â€“ futtasd a news_sentiment.py-t.")

# â•”â•â•â•â•â•â•â•â•â•  SHAP-szerÅ± Feature HatÃ¡sok  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
if not df_firm.empty:
    top_firm = df_firm.nlargest(1, "firm_score").iloc[0]
    shap_vals = next(
        (f.get("firm_shap") for f in df_firm.to_dict("records")
         if f["ticker"] == top_firm["ticker"] and f.get("firm_shap")),
        None
    )

    if shap_vals:
        st.subheader(f"SHAP-szerÅ± Feature HatÃ¡sok â€“ {top_firm['ticker']}")
        shap_df = (pd.DataFrame(
            [{"Feature": k, "SHAP": v} for k, v in shap_vals.items()])
            .sort_values("SHAP")
        )
        st.plotly_chart(
            px.bar(shap_df, x="SHAP", y="Feature", orientation="h",
                   title=f"{top_firm['ticker']} â€“ Feature Contributions"),
            use_container_width=True
        )
    else:
        st.info(
            f"Nincs SHAP-adata a(z) {top_firm['ticker']} szÃ¡mÃ¡ra â€“ "
            "futtasd Ãºjra a firm-promptot."
        )

# â•”â•â•â•â•â•â•â•â•â•  15-Asset Allocation  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
if PORT_FILE.exists():
    port = json.load(open(PORT_FILE))
    st.subheader("Current 15-asset Allocation")
    alloc_df = pd.DataFrame(port["table"])
    st.dataframe(alloc_df, use_container_width=True)

    if not alloc_df.empty:
        st.plotly_chart(
            px.bar(alloc_df.sort_values("Weight (%)"),
                   x="Weight (%)", y="Asset", orientation="h",
                   title="Portfolio Allocation Weights"),
            use_container_width=True
        )

# â•”â•â•â•â•â•â•â•â•â•  Buy & Hold Back-test  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
df_bh_eq = read_json(BH_EQ_FILE)
df_bh_st = read_json(BH_ST_FILE)
if not df_bh_eq.empty and not df_bh_st.empty:
    st.header("Performance Back-test â€“ Buy & Hold")
    fig_bh = go.Figure()
    for col in df_bh_eq.columns:
        fig_bh.add_scatter(x=df_bh_eq.index, y=df_bh_eq[col], name=col)
    fig_bh.update_layout(xaxis_title="Date", yaxis_title="Value (USD)")
    st.plotly_chart(fig_bh, use_container_width=True)
    st.table(df_bh_st.T)

# â•”â•â•â•â•â•â•â•â•â•  Monthly Rebalance Back-test  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
df_reb_eq = read_json(REB_EQ_FILE)
df_reb_st = read_json(REB_ST_FILE)
if not df_reb_eq.empty and not df_reb_st.empty:
    st.subheader("Monthly Rebalance Back-test")
    fig_reb = go.Figure()
    for col in df_reb_eq.columns:
        style = dict(dash="dot") if col.upper() == "SPY" else {}
        fig_reb.add_scatter(x=df_reb_eq.index, y=df_reb_eq[col],
                            name=col, line=style)
    fig_reb.update_layout(xaxis_title="Date", yaxis_title="Value (USD)")
    st.plotly_chart(fig_reb, use_container_width=True)
    st.table(df_reb_st.T)

# â•”â•â•â•â•â•â•â•â•â•  Risk-Budget vs. LLM Weights  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
df_rb = read_json(RISK_FILE)
if not df_rb.empty and PORT_FILE.exists():
    df_rb["ticker"] = df_rb["ticker"].str.strip()
    df_llm = (
        pd.DataFrame(port["table"])
        [["Asset", "Weight (%)"]]
        .rename(columns={"Asset": "ticker", "Weight (%)": "llm_w"})
        .assign(ticker=lambda d: d["ticker"].str.strip())
    )
    merged = df_llm.merge(df_rb, on="ticker", how="inner")
    if not merged.empty:
        st.subheader("LLM vs. Risk-Budget Weights")
        st.dataframe(merged.set_index("ticker"))
        fig_cmp = go.Figure()
        fig_cmp.add_bar(x=merged["ticker"], y=merged["llm_w"], name="LLM")
        fig_cmp.add_bar(x=merged["ticker"], y=merged["weight"], name="Risk-Budget")
        fig_cmp.update_layout(barmode="group",
                              xaxis_title="Ticker",
                              yaxis_title="Weight (%)")
        st.plotly_chart(fig_cmp, use_container_width=True)
    else:
        st.info("Ticker-mezÅ‘k nem egyeznek â€“ ellenÅ‘rizd a JSON-ok formÃ¡tumÃ¡t.")
else:
    st.info("Risk-budget fÃ¡jl hiÃ¡nyzik â€“ futtasd a risk_budget.py-t.")-e \n\n=== FILE: ./news_sentiment.py ===
#!/usr/bin/env python3
"""
StockNews: 7-napos Ã¡tlagolt hÃ­r-szentiment
Positive = +1 Â· Neutral = 0 Â· Negative = â€“1
Cut-off: avg < â€“0.05 â†’ sÃºly â€“30 %
"""
import os, json, requests, time
from pathlib import Path
from dotenv import load_dotenv

load_dotenv() 

BASE  = Path(__file__).resolve().parent
PORT  = json.load(open(BASE/"outputs/portfolio_latest.json"))["table"]
API   = os.getenv("STOCKNEWS_API_KEY")

LABEL2SCORE = {"Positive": 1.0, "Neutral": 0.0, "Negative": -1.0}

# news_sentiment.py â€“ csak a URL Ã©s a DEBUG mÃ³dosul
def avg_sentiment(tkr):
    url = (
        "https://stocknewsapi.com/api/v1"
        f"?tickers={tkr}&items=100&date=last7days&token={API}"
    )
    js = requests.get(url, timeout=30).json()
    if not js.get("data"):        # DEBUG
        print("âš ï¸", tkr, "â†’", js.get("message") or "0 articles")
        return None
    scores = [
        {"Positive": 1, "Neutral": 0, "Negative": -1}.get(a["sentiment"], 0)
        for a in js["data"] if a.get("sentiment")
    ]
    return sum(scores)/len(scores) if scores else None

out = []
for row in PORT:
    tkr = row["Asset"].strip().upper()
    s   = avg_sentiment(tkr)
    if s is not None:
        out.append({"ticker": tkr, "avg_sent": round(s, 3)})
    time.sleep(0.2)         # 5 req/sec limit

Path(BASE/"outputs").mkdir(exist_ok=True)
json.dump(out, open(BASE/"outputs/news_sentiment.json","w"), indent=2)
print(f"âœ… {len(out)} sentiment-sor mentve â€¢ outputs/news_sentiment.json")-e \n\n=== FILE: ./risk_budget.py ===
#!/usr/bin/env python3
"""
Risk-budget + Black-Litterman overlay

1. 60-napos rolling volatilitÃ¡s alapjÃ¡n inverse-vol sÃºlyok (defenzÃ­v)
2. BL-modell: egyensÃºlyi sÃºly = inv-vol, â€vÃ©lemÃ©nyâ€ = firm_score-bÅ‘l szÃ¡rmazÃ³
   relatÃ­v hozamelvÃ¡rÃ¡s (0â€“3% skÃ¡lÃ¡zva)
3. 50-50 blend â†’ vÃ©gsÅ‘ risk-budget sÃºlyok

Kimenet: outputs/portfolio_risk_budget.json   [{ticker, weight %}, â€¦]
"""

import json, datetime, numpy as np, pandas as pd
from pathlib import Path
from pandas_datareader import data as pdr

# â”€â”€ FÃ¡jl-Ãºtvonalak â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE = Path(__file__).resolve().parent
PORT_FILE  = BASE / "outputs/portfolio_latest.json"
FIRM_FILE  = BASE / "inputs/firm_inputs.json"
OUT_FILE   = BASE / "outputs/portfolio_risk_budget.json"

# â”€â”€ BeÃ¡llÃ­tÃ¡sok â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
START  = "2024-01-01"
END    = datetime.date.today().isoformat()
VOL_WIN = 60          # nap
BL_TAU  = 0.05
VIEW_SCALE = 0.03     # max 3% excess return
BL_BLEND   = 0.5      # 0=csak inv-vol, 1=csak BL

# â”€â”€ Adatok beolvasÃ¡sa â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PORT = json.load(open(PORT_FILE))["table"]
FIRMS = json.load(open(FIRM_FILE))

tickers = [row["Asset"].strip().upper() for row in PORT]
score_map = {f["ticker"].upper(): f["firm_score"] or 0 for f in FIRMS}

# â”€â”€ Ãrfolyamok Stooq-rÃ³l â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
px = pdr.DataReader([t + ".US" for t in tickers], "stooq", START, END)["Close"]
px.columns = [c.split(".")[0] for c in px.columns]
px = px.dropna(how="all")

# HiÃ¡nyzÃ³ Ã¡rak â€“ tÃ¶rÃ¶ljÃ¼k a tickert Ã©s a score-t is
missing = [t for t in tickers if t not in px.columns]
if missing:
    print("âš ï¸  HiÃ¡nyzÃ³ Ã¡rfolyam:", missing)
    px = px.drop(columns=missing, errors="ignore")
    tickers = [t for t in tickers if t not in missing]

# â”€â”€ 1) Inverse-vol sÃºlyok â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
vol = px.pct_change().rolling(VOL_WIN).std().iloc[-1]
inv_vol_w = (1 / vol) / (1 / vol).sum()

# â”€â”€ 2) Black-Litterman szÃ¡mÃ­tÃ¡s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#   â€” EgyensÃºlyi sÃºly (m): inv-vol
#   â€” NÃ©zetek: firm_score â†’ 0-1 skÃ¡la â†’ *VIEW_SCALE hozamelvÃ¡rÃ¡s
raw_scores = np.array([score_map.get(t, 0) for t in tickers])
min_s, max_s = raw_scores.min(), raw_scores.max()
views = (raw_scores - min_s) / (max_s - min_s) if max_s > min_s else raw_scores
Q = views * VIEW_SCALE                # vÃ¡rt excess return

# SzÃ³rÃ¡s-mÃ¡trix Ã©vesÃ­tve
cov = px.pct_change().cov().values * 252
P   = np.eye(len(tickers))
tau = BL_TAU
eq_w = inv_vol_w.values
Pi = cov @ eq_w                       # piaci risk premium (proxy)

# BL zÃ¡rt formula
M = np.linalg.inv(np.linalg.inv(tau * cov) + P.T @ P / 0.25)
adj_ret = M @ (np.linalg.inv(tau * cov) @ Pi + P.T @ Q / 0.25)

# Max-Sharpe portfÃ³liÃ³ (risk-aversion = 1)
w_bl = np.linalg.inv(cov) @ adj_ret
w_bl = w_bl / w_bl.sum()              # normÃ¡lÃ¡s 1-re

# â”€â”€ 3) VÃ©gsÅ‘ blend â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
w_final = BL_BLEND * w_bl + (1 - BL_BLEND) * inv_vol_w
w_final = w_final / w_final.sum()

# â”€â”€ MentÃ©s â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
out = [
    {"ticker": t, "weight": round(float(w) * 100, 2)}
    for t, w in zip(tickers, w_final)
]

Path(OUT_FILE).parent.mkdir(exist_ok=True)
json.dump(out, open(OUT_FILE, "w"), indent=2)
print("âœ… Risk-budget sÃºlyok mentve â†’", OUT_FILE.relative_to(BASE))-e \n\n=== FILE: ./data_fetch/fetch_data.py ===
#!/usr/bin/env python3
"""
EgyszerÅ±sÃ­tett input-generÃ¡lÃ¡s:
  â€¢ sector_inputs.json  â€“ minden szektor (config.yaml)
  â€¢ firm_inputs.json    â€“ csak override_tickers alapjÃ¡n
Nem hÃ­v Yahoo holdings-API-t / scrape-et!
"""

import os, json, datetime, requests, yfinance as yf
from pathlib import Path
import yaml
from dotenv import load_dotenv
from fredapi import Fred

BASE = Path(__file__).resolve().parent.parent   # projekt gyÃ¶kere
load_dotenv(override=True)

# --- API-kulcsok
FRED_KEY      = os.getenv("FRED_API_KEY")
STOCKNEWS_KEY = os.getenv("STOCKNEWS_API_KEY")
fred = Fred(api_key=FRED_KEY)

CFG   = yaml.safe_load(open(BASE / "config.yaml"))
TODAY = datetime.date.today().isoformat()

# ---------- Helper fÃ¼ggvÃ©nyek -----------------------------------------------
def fred_latest(series_id):
    return float(fred.get_series_latest_release(series_id).dropna().iloc[-1])

def macro_indicators():
    return {
        "GDP": round(fred_latest("GDP") / 1_000, 2),   # USD-billion
        "CPI": round(fred_latest("CPIAUCSL"), 2),
        "Unemployment": round(fred_latest("UNRATE"), 2),
        "InterestRate": round(fred_latest("FEDFUNDS"), 2),
    }

def stocknews(ticker_or_kw, items=3):
    url = "https://stocknewsapi.com/api/v1"
    params = {"tickers": ticker_or_kw, "items": items, "token": STOCKNEWS_KEY}
    resp = requests.get(url, params=params, timeout=30)
    return [a["title"] for a in resp.json().get("data", [])] if resp.ok else []

def firm_fundamentals(ticker):
    info = yf.Ticker(ticker).info
    mapping = {
        "trailingPE": "P/E",
        "pegRatio": "PEG",
        "beta": "Beta",
        "returnOnEquity": "ROE",
        "quickRatio": "Quick Ratio",
    }
    out = {}
    for k, new in mapping.items():
        v = info.get(k)
        if v is not None:
            out[new] = round(v, 2)
    return out

# ---------- Main ------------------------------------------------------------
def main():
    sector_inputs, firm_inputs = [], []
    macro_json = macro_indicators()

    for s in CFG["sectors"]:
        # --- Sector record ------------------------------
        sector_inputs.append({
            "name": s["name"],
            "macro_indicators_json": macro_json,
            "sector_news_snippets": stocknews(s["keyword"]),
            "today": TODAY,
            "sector_score": ""
        })

        # --- Firm records (csak override_tickers) -------
        tickers = s.get("override_tickers", [])
        for tkr in tickers:
            firm_inputs.append({
                "sector": s["name"],
                "ticker": tkr,
                "company_name": tkr,
                "industry": s["name"].title(),
                "firm_financials_json": firm_fundamentals(tkr),
                "firm_news_snippets": stocknews(tkr),
                "today": TODAY,
                "firm_score": ""
            })

    Path(BASE / "inputs").mkdir(exist_ok=True)
    json.dump(sector_inputs, open(BASE / "inputs/sector_inputs.json", "w"), indent=2)
    json.dump(firm_inputs,   open(BASE / "inputs/firm_inputs.json",   "w"), indent=2)
    print(f"âœ… {len(sector_inputs)} sector, {len(firm_inputs)} firm input mentve.")

if __name__ == "__main__":
    main()-e \n\n=== FILE: ./data_fetch/helpers.py ===
-e \n\n=== FILE: ./backtest.py ===
#!/usr/bin/env python3
"""
Backtest Stooq EOD Ã¡rak alapjÃ¡n (nincs API-kulcs, nincs rate-limit)

Kimenet:
    outputs/backtest_equity.json
    outputs/backtest_stats.json
"""
import importlib, types
try:
    import distutils
except ModuleNotFoundError:
    import types, sys
    import setuptools._distutils as _d
    sys.modules['distutils'] = _d
    sys.modules['distutils.version'] = _d.version
    
import json, datetime, pandas as pd
from pathlib import Path
from pandas_datareader import data as pdr   # â† Stooq forrÃ¡s

BASE = Path(__file__).resolve().parent
PORT = json.load(open(BASE / "outputs/portfolio_latest.json"))["table"]

# ---- ParamÃ©terek -----------------------------------------------------------
START = "2023-01-01"
END   = datetime.date.today().isoformat()
BENCH = "SPY"
UNIT  = 1_000_000        # indulÃ³ portfÃ³liÃ³ USD

# ---- Ticker & Weight tisztÃ­tÃ¡s ---------------------------------------------
def clean(t): return t.replace("\xa0", "").strip().upper()
weights = {clean(r["Asset"]): float(r["Weight (%)"])/100 for r in PORT}
tickers = list(weights) + [BENCH]

# Stooq ticker formÃ¡tum: "AAPL.US"
stooq_syms = [t + ".US" for t in tickers]

print("â†’ LetÃ¶ltÃ©s Stooq-rÃ³l â€¦")
px = (
    pdr.DataReader(stooq_syms, "stooq", START, END)["Close"]
    .rename(columns=lambda c: c.split(".")[0])   # "AAPL.US" â†’ "AAPL"
    .dropna(how="all")
)

# ---- HiÃ¡nyzÃ³ ticker(ek) kezelÃ©se -------------------------------------------
missing = [t for t in weights if t not in px.columns]
if missing:
    print(f"âš ï¸  HiÃ¡nyzÃ³ Ã¡rfolyam: {missing} â€“ sÃºlyok tÃ¶rlÃ©se")
    for t in missing: weights.pop(t)
if not weights:
    raise RuntimeError("Nincs Ã©rvÃ©nyes Ã¡rfolyam â€“ backtest megszakÃ­tva.")

# ---- Portfolio equity -------------------------------------------------------
alloc_qty = {t: weights[t] * UNIT / px[t].iloc[0] for t in weights}
equity = (px[list(weights)] * pd.Series(alloc_qty)).sum(axis=1)
bench  = px[BENCH] / px[BENCH].iloc[0] * UNIT

# ---- StatisztikÃ¡k -----------------------------------------------------------
def cagr(ts):
    yrs = (ts.index[-1] - ts.index[0]).days / 365.25
    return (ts.iloc[-1] / ts.iloc[0]) ** (1 / yrs) - 1

def max_dd(ts):
    roll = ts.cummax()
    return (ts / roll - 1).min()

def sharpe(ts):
    ret = ts.pct_change().dropna()
    return (ret.mean() / ret.std()) * (252 ** 0.5)

stats = {
    "Portfolio": {
        "CAGR":   round(cagr(equity) * 100, 2),
        "MaxDD":  round(max_dd(equity) * 100, 2),
        "Sharpe": round(sharpe(equity), 2),
    },
    "Benchmark": {
        "CAGR":   round(cagr(bench) * 100, 2),
        "MaxDD":  round(max_dd(bench) * 100, 2),
        "Sharpe": round(sharpe(bench), 2),
    },
}

# ---- MentÃ©s -----------------------------------------------------------------
out_dir = BASE / "outputs"; out_dir.mkdir(exist_ok=True)
pd.DataFrame({"Portfolio": equity, BENCH: bench}).to_json(
    out_dir / "backtest_equity.json",
    orient="split",
    date_format="iso",
)
json.dump(stats, open(out_dir / "backtest_stats.json", "w"), indent=2)

print("âœ… Backtest kÃ©sz â€¢ files in outputs/")-e \n\n=== FILE: ./generator_runner.py ===
#!/usr/bin/env python3
"""
PortfÃ³liÃ³-generÃ¡tor
â€¢ Beolvassa az aktuÃ¡lis firm-score listÃ¡t (inputs/firm_inputs.json)
â€¢ Top 15 alapjÃ¡n promptot futtat a Generator LLM-mel
â€¢ SÃºlyokat hÃ­r-szentimenttel korrigÃ¡lja (StockNews 7-napos Ã¡tlag)
â€¢ Kimenet: outputs/portfolio_latest.json
"""

import os, json, re
from pathlib import Path
from io import StringIO

import yaml
import pandas as pd
from dotenv import load_dotenv
from jinja2 import Template
from openai import OpenAI

# â”€â”€ Konstansok / fÃ¡jl-Ãºtvonalak â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE  = Path(__file__).resolve().parent
INPUT = BASE / "inputs"
OUT   = BASE / "outputs"
PROMPT_DIR = BASE / "prompts"

load_dotenv(override=True)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
MODEL  = os.getenv("OPENAI_MODEL", "gpt-4o")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Top 15 firm kivÃ¡lasztÃ¡sa
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
firm_records = json.load(open(INPUT / "firm_inputs.json"))
top_firms = sorted(
    firm_records,
    key=lambda x: x["firm_score"] or 0,
    reverse=True
)[:15]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ETF-univerzum (config.yaml)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cfg_sectors = yaml.safe_load(open(BASE / "config.yaml"))["sectors"]
etf_list = [s["etf"] for s in cfg_sectors if "etf" in s]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. HÃ­r-szentiment beolvasÃ¡sa Ã©s sÃºlykorrekciÃ³
#    âˆ’30 % vÃ¡gÃ¡s, ha 7-napos Ã¡tlag < â€“0.05
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sentiment_path = OUT / "news_sentiment.json"
sent_map = {}
if sentiment_path.exists():
    sent_map = {d["ticker"].upper(): d["avg_sent"] for d in json.load(open(sentiment_path))}

NEG_TH = -0.05     # kÃ¼szÃ¶b
CUT    = 0.30      # 30 % sÃºlycsÃ¶kkentÃ©s

for row in top_firms:
    tkr = row["ticker"].upper()
    s   = sent_map.get(tkr)
    if s is not None and s < NEG_TH:
        # eredeti sÃºly a Generator promptban szereplÅ‘ "Weight (%)" kulcsszÃ³val
        row["Weight (%)"] = round(row.get("Weight (%)", 10) * (1 - CUT), 2)
        # â€œEdgeâ€ oszlop kiegÃ©szÃ­tÃ©se jelzÃ©ssel
        row["Edge"] = row.get("Edge", "") + f" | SENTIMENTâ†“{s}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Prompt-input Ã¶sszeÃ¡llÃ­tÃ¡sa
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
generator_input = {
    "top_firms_list": [
        {
            "name":  f["ticker"],
            "score": f["firm_score"],
            "thesis": f.get("Edge", "Top-ranked firm"),
            "weight": f.get("Weight (%)", 10)
        }
        for f in top_firms
    ],
    "macro_forecast_table": {"Note": "Auto-generated run"},
    "etf_universe_list": etf_list,
    "today": top_firms[0]["today"]
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. Prompt futtatÃ¡s OpenAI-val
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
prompt_tpl = Template(open(PROMPT_DIR / "generator_prompt.j2").read())
prompt = prompt_tpl.render(**generator_input)

response = client.chat.completions.create(
    model=MODEL,
    messages=[{"role": "user", "content": prompt}],
    temperature=0,
    max_tokens=900
).choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. Markdownâ†’DataFrame konvertÃ¡lÃ¡s
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
clean_lines = [
    ln for ln in response.splitlines()
    if "|" in ln and not re.match(r"^\s*\|[-:]+\|", ln)
]
md = "\n".join(clean_lines)
df = pd.read_csv(StringIO(md), sep="\\|", engine="python").dropna(axis=1, how="all").iloc[1:]
df.columns = [c.strip() for c in df.columns]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. Kimenet JSON-fÃ¡jlba
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
portfolio_json = {
    "date": generator_input["today"],
    "table": df.to_dict(orient="records")
}

OUT.mkdir(exist_ok=True)
json.dump(portfolio_json, open(OUT / "portfolio_latest.json", "w"), indent=2)

print("âœ… PortfÃ³liÃ³ mentve: outputs/portfolio_latest.json")